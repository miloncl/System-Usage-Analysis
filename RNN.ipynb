{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sqlite3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for RNN\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "time_df = []\n",
    "\n",
    "for filename in os.listdir(filepath):\n",
    "    if 'temp' in filename:\n",
    "        continue\n",
    "    if filename == '.ipynb_checkpoints':\n",
    "        continue\n",
    "    cnx = sqlite3.connect(filepath + filename)\n",
    "    cnx.text_factory = lambda b: b.decode(errors = 'ignore') #https://stackoverflow.com/questions/22751363/sqlite3-operationalerror-could-not-decode-to-utf-8-column\n",
    "    df_string = pd.read_sql_query(\"SELECT * FROM COUNTERS_STRING_TIME_DATA\", cnx)\n",
    "    df_ull = pd.read_sql_query(\"SELECT * FROM COUNTERS_ULL_TIME_DATA\", cnx)\n",
    "    df_data = pd.concat([df_string, df_ull], ignore_index = True)\n",
    "    start_val = pd.DataFrame({'MEASUREMENT_TIME': df_data.loc[0][0], 'ID_INPUT': 4, 'VALUE': 's0', 'PRIVATE_DATA': 0}, index =[0])\n",
    "    df_data = pd.concat([start_val, df_data])\n",
    "    data.append(pd.DataFrame(df_data))\n",
    "    schema = pd.DataFrame(pd.read_sql_query(\"SELECT * FROM INPUTS\", cnx))\n",
    "    \n",
    "    # get actual start time\n",
    "    time_diff = pd.read_sql_query(\"SELECT * FROM DB_META_DATA\", cnx)\n",
    "    utc_open = pd.to_datetime(time_diff[time_diff['KEY'] == 'OPEN_TIME_UTC']['VALUE'].iloc[0])\n",
    "    local_open = pd.to_datetime(time_diff[time_diff['KEY'] == 'OPEN_TIME_LOCAL']['VALUE'].iloc[0])\n",
    "    time_difference = utc_open - local_open\n",
    "    \n",
    "    time_sub = df_data[df_data['ID_INPUT'] == 4].copy()\n",
    "    time_sub['MEASUREMENT_TIME'] = pd.to_datetime(time_sub['MEASUREMENT_TIME'])\n",
    "    time_sub['MEASUREMENT_TIME'] = time_sub['MEASUREMENT_TIME'] - time_difference\n",
    "    time_sub['Time_Used'] = time_sub['MEASUREMENT_TIME'].diff().dt.total_seconds()\n",
    "    time_sub['Time_Used'] = time_sub['Time_Used'].shift(periods = -1)\n",
    "    time_sub = time_sub.drop(columns = ['PRIVATE_DATA', 'ID_INPUT'])\n",
    "    time_df.append(time_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(data, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MEASUREMENT_TIME'] = pd.to_datetime(df['MEASUREMENT_TIME'])\n",
    "df['PRIVATE_DATA'] = df['PRIVATE_DATA'].astype(int)\n",
    "df['VALUE'] = df['VALUE'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "all_time_df = pd.concat(time_df, ignore_index = True)\n",
    "all_time_df = all_time_df.fillna(0)\n",
    "all_time_df['Hour'] = all_time_df['MEASUREMENT_TIME'].dt.hour\n",
    "all_time_df['Date'] = all_time_df[\"MEASUREMENT_TIME\"].astype(str).apply(lambda x: x[:10])\n",
    "all_time_df['Minute'] = all_time_df['MEASUREMENT_TIME'].dt.minute\n",
    "all_time_df['Day'] = all_time_df['MEASUREMENT_TIME'].dt.day\n",
    "all_time_df['Month'] = all_time_df['MEASUREMENT_TIME'].dt.month\n",
    "all_time_df['Day_Week'] = all_time_df['MEASUREMENT_TIME'].dt.day_name()\n",
    "all_time_df = all_time_df.assign(Week_Year = all_time_df['MEASUREMENT_TIME'].apply(lambda x: x.strftime(\"%W\")))\n",
    "all_time_df = all_time_df.assign(Week_Day = all_time_df['Week_Year'] + '_' + all_time_df['Day_Week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_per_week_day = all_time_df.copy()\n",
    "time_per_week_day['Time_Used'] = time_per_week_day['Time_Used'] / 60 / 60\n",
    "time_per_week_day = time_per_week_day.groupby(\"Week_Day\").apply(lambda x: x.groupby(\"VALUE\")[\"Time_Used\"].sum())\n",
    "time_per_week_day = pd.DataFrame(time_per_week_day).reset_index(level=1, inplace=False)\n",
    "df_pivot = time_per_week_day.pivot_table(index = 'Week_Day', columns='VALUE', values='Time_Used').fillna(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "import datetime\n",
    "from datetime import timedelta, date\n",
    "\n",
    "def date_range(start, end):\n",
    "    dates = []\n",
    "    delta = end - start\n",
    "    for i in range(delta.days + 2):\n",
    "        date = start + timedelta(days=i)\n",
    "        date = date.strftime(\"%Y-%m-%d\")\n",
    "        dates.append(date)\n",
    "    return dates\n",
    "\n",
    "all_columns = [x for x in range(0,24)]\n",
    "all_columns.append('Total_Usage')\n",
    "all_index = date_range(all_time_df['MEASUREMENT_TIME'].min(), all_time_df['MEASUREMENT_TIME'].max())\n",
    "apps = {}\n",
    "for app_name in all_time_df['VALUE'].unique():\n",
    "    if app_name == 's0':\n",
    "        continue\n",
    "    app = all_time_df[all_time_df['VALUE'] == app_name]\n",
    "    #print(app)\n",
    "    app = app.reset_index()\n",
    "    zero_data = np.zeros(shape=(len(all_index),len(all_columns)))\n",
    "    app_df = pd.DataFrame(zero_data, index = all_index, columns = all_columns)\n",
    "    for x in range(len(app)):\n",
    "        timestamp = app.loc[x][\"MEASUREMENT_TIME\"]\n",
    "        usage = app.loc[x]['Time_Used']\n",
    "        end_timestamp = timestamp + datetime.timedelta(seconds = usage)\n",
    "        start_hour = app.loc[x]['Hour']\n",
    "        end_hour = int(end_timestamp.strftime(\"%H\"))\n",
    "        date = app.loc[x]['Date']\n",
    "        if start_hour == end_hour:\n",
    "            app_df.loc[date][start_hour] += usage\n",
    "            app_df.loc[date]['Total_Usage'] += usage\n",
    "        else:\n",
    "            remaining_seconds = 3600 - (app.loc[x]['Minute'] * 60 + int(timestamp.strftime(\"%S\")))\n",
    "            app_df.loc[date][start_hour] += remaining_seconds\n",
    "            app_df.loc[date]['Total_Usage'] += remaining_seconds\n",
    "            overflow = usage - remaining_seconds\n",
    "            curr_hour = start_hour + 1\n",
    "            while overflow > 3600:\n",
    "                if curr_hour > 23:\n",
    "                    date = app.loc[x][\"MEASUREMENT_TIME\"] + datetime.timedelta(days = 1)\n",
    "                    date = date.strftime(\"%Y-%m-%d\")\n",
    "                    curr_hour = 0\n",
    "                app_df.loc[date][curr_hour] += 3600\n",
    "                app_df.loc[date]['Total_Usage'] += 3600\n",
    "                curr_hour = curr_hour + 1\n",
    "                overflow -= 3600\n",
    "\n",
    "            if curr_hour > 23:\n",
    "                date = app.loc[x][\"MEASUREMENT_TIME\"] + datetime.timedelta(days = 1)\n",
    "                date = date.strftime(\"%Y-%m-%d\")\n",
    "                curr_hour = 0\n",
    "            app_df.loc[date][curr_hour] += overflow\n",
    "            app_df.loc[date]['Total_Usage'] += overflow\n",
    "            \n",
    "    apps[app_name] = app_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>Total_Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2395.514</td>\n",
       "      <td>599.682</td>\n",
       "      <td>1613.008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1327.671</td>\n",
       "      <td>3440.171</td>\n",
       "      <td>3354.687</td>\n",
       "      <td>3560.505</td>\n",
       "      <td>3545.317</td>\n",
       "      <td>34029.454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...        15       16  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  2395.514  599.682   \n",
       "\n",
       "         17   18        19        20        21        22        23  \\\n",
       "0  1613.008  0.0  1327.671  3440.171  3354.687  3560.505  3545.317   \n",
       "\n",
       "   Total_Usage  \n",
       "0    34029.454  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apps['chrome.exe'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>Total_Usage</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>599.682</td>\n",
       "      <td>1613.008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1327.671</td>\n",
       "      <td>3440.171</td>\n",
       "      <td>3354.687</td>\n",
       "      <td>3560.505</td>\n",
       "      <td>3545.317</td>\n",
       "      <td>34029.454</td>\n",
       "      <td>2023-01-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...       16        17  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  599.682  1613.008   \n",
       "\n",
       "    18        19        20        21        22        23  Total_Usage  \\\n",
       "0  0.0  1327.671  3440.171  3354.687  3560.505  3545.317    34029.454   \n",
       "\n",
       "         date  \n",
       "0  2023-01-15  \n",
       "\n",
       "[1 rows x 26 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apps['chrome.exe']['date'] = all_time_df['Date'].unique()\n",
    "apps['chrome.exe'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps['chrome.exe']['Day_Week'] = pd.to_datetime(pd.Series(all_time_df['Date'].unique())).dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>Total_Usage</th>\n",
       "      <th>date</th>\n",
       "      <th>Day_Week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1613.008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1327.671</td>\n",
       "      <td>3440.171</td>\n",
       "      <td>3354.687</td>\n",
       "      <td>3560.505</td>\n",
       "      <td>3545.317</td>\n",
       "      <td>34029.454</td>\n",
       "      <td>2023-01-15</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...        17   18  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  1613.008  0.0   \n",
       "\n",
       "         19        20        21        22        23  Total_Usage        date  \\\n",
       "0  1327.671  3440.171  3354.687  3560.505  3545.317    34029.454  2023-01-15   \n",
       "\n",
       "   Day_Week  \n",
       "0    Sunday  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apps['chrome.exe'].head(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a). One-hot the day-of-the-week (Mon,...) and sin(hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oh_day_sin_hr(apps, app_name):\n",
    "    day = 24\n",
    "    hours_incr = np.arange(24) + 1\n",
    "    sin_hrs = np.round(np.sin(hours_incr * (np.pi / day)),3)\n",
    "    \n",
    "    one_hot_day_encoded = {\n",
    "        'Monday': [1,0,0,0,0,0,0],\n",
    "        'Tuesday': [0,1,0,0,0,0,0],\n",
    "        'Wednesday': [0,0,1,0,0,0,0],\n",
    "        'Thursday': [0,0,0,1,0,0,0],\n",
    "        'Friday': [0,0,0,0,1,0,0],\n",
    "        'Saturday': [0,0,0,0,0,1,0],\n",
    "        'Sunday': [0,0,0,0,0,0,1]\n",
    "    }\n",
    "    apps[app_name]['date'] = all_time_df['Date'].unique()\n",
    "    apps[app_name]['Day_Week'] = pd.to_datetime(pd.Series(all_time_df['Date'].unique())).dt.day_name()\n",
    "    apps[app_name]['Day_Week'] = apps[app_name]['Day_Week'].apply(lambda x: one_hot_day_encoded[x])\n",
    "\n",
    "    vanilla_df = apps[app_name]\n",
    "    X = []\n",
    "    y = np.array([])\n",
    "    for row in vanilla_df.iterrows():\n",
    "        #print(row[1])\n",
    "        feats = []\n",
    "        for hr in sin_hrs:\n",
    "            feats = feats + [np.append(hr, row[1]['Day_Week'])]\n",
    "        targets = row[1][:24]\n",
    "        #print(np.array(feats).shape)\n",
    "        X = X + feats\n",
    "        y = np.append(y, np.array(targets))\n",
    "    \n",
    "    X = np.array(X)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = oh_day_sin_hr(apps, 'VsDebugConsole.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['VsDebugConsole.exe', 'explorer.exe', 'devenv.exe', 'ApplicationFrameHost.exe', 'chrome.exe', 'ShellExperienceHost.exe', 'SearchApp.exe', 'Unable To Open Process', 'SnippingTool.exe', 'DB Browser for SQLite.exe', 'Code.exe', 'CodeSetup-stable-97dec172d3256f8ca4bfb2143f3f76b503ca0534.tmp', 'IDMan.exe', 'msedge.exe', 'rstudio.exe', 'mintty.exe', 'Zoom.exe', 'Installer.exe', 'TeamViewer.exe', 'mshta.exe', 'GoogleDriveFS.exe', 'GitHub.UI.exe', 'rundll32.exe', 'OpenWith.exe', 'StartMenuExperienceHost.exe', 'Update.exe', 'GitHubDesktop.exe', 'CodeSetup-stable-e2816fe719a4026ffa1ee0189dc89bdfdbafb164.tmp', 'cmd.exe', 'CodeSetup-stable-441438abd1ac652551dbe4d408dfcec8a499b8bf.tmp'])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apps.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Sin(hrs) only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sin_hr(apps, app_name):\n",
    "    day = 24\n",
    "    hours_incr = np.arange(24) + 1\n",
    "    sin_hrs = np.round(np.sin(hours_incr * (np.pi / day)),3)\n",
    "\n",
    "    vanilla_df = apps[app_name]\n",
    "    X = []\n",
    "    y = np.array([])\n",
    "    for row in vanilla_df.iterrows():\n",
    "        #print(row[1])\n",
    "        feats = []\n",
    "        for hr in sin_hrs:\n",
    "            feats = feats + [hr]\n",
    "        targets = row[1][:24]\n",
    "        #print(np.array(feats).shape)\n",
    "        X = X + feats\n",
    "        y = np.append(y, np.array(targets))\n",
    "    \n",
    "    X = np.array(X)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = sin_hr(apps, 'chrome.exe')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try the features on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Device Configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(batch_size):\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2/(1-0.2), shuffle=False)\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = X_train, X_val, X_test, np.array(y_train).reshape(-1,1), np.array(y_val).reshape(-1,1), np.array(y_test).reshape(-1,1)\n",
    "\n",
    "    scaler = MinMaxScaler() \n",
    "    y_train_scaled = scaler.fit_transform(y_train)\n",
    "    y_val_scaled = scaler.fit_transform(y_val)\n",
    "    y_test_scaled = scaler.fit_transform(y_test)\n",
    "\n",
    "    # Data into tensor\n",
    "    train_X = torch.Tensor(X_train)\n",
    "    train_y = torch.Tensor(y_train_scaled)\n",
    "    #train_y = torch.Tensor(np.array(y_train, dtype=float))\n",
    "\n",
    "    val_X = torch.Tensor(X_val)\n",
    "    val_y = torch.Tensor(y_val_scaled)\n",
    "    #val_y = torch.Tensor(np.array(y_val, dtype=float))\n",
    "\n",
    "    test_X = torch.Tensor(X_test)\n",
    "    test_y = torch.Tensor(y_test_scaled)\n",
    "    #test_y = torch.Tensor(np.array(y_test_scaled, dtype=float))\n",
    "\n",
    "    train = TensorDataset(train_X, train_y)\n",
    "    val = TensorDataset(val_X, val_y)\n",
    "    test = TensorDataset(test_X, test_y)\n",
    "        \n",
    "    batch_size = 1\n",
    "    train_loader = DataLoader(train, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "    val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "    test_loader = DataLoader(test, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "    test_loader_one = DataLoader(test, batch_size=1, shuffle=False, drop_last=True)\n",
    "\n",
    "    print(len(train_loader.dataset))\n",
    "    print(len(val_loader.dataset))\n",
    "    print(len(test_loader.dataset))\n",
    "    print(len(test_loader_one.dataset))\n",
    "\n",
    "    return train_loader, val_loader, test_loader, test_loader_one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "446\n",
      "149\n",
      "149\n",
      "149\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader, test_loader_one = prep_data(15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dumpster 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simpleRNN(nn.Module):\n",
    "    def __init__(self, in_dims, hidden_size, out_dims):\n",
    "        super(simpleRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.in_to_hidden = nn.Linear()\n",
    "        self.in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simpleRNN(nn.Module):\n",
    "    def __init__(self, input_dims, hidden_dims, num_layers):\n",
    "        super(simpleRNN, self).__init__()\n",
    "        self.simpleRNN = nn.RNN(input_dims, hidden_dims, num_layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.simpleRNN(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 8\n",
    "hidden_size = 5\n",
    "batch_size = 15\n",
    "num_layers = 1\n",
    "learning_rate = 0.001\n",
    "num_iter = 50 \n",
    "\n",
    "model = simpleRNN(input_size, hidden_size, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input must have 3 dimensions, got 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-120-104648cf5c4d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-106-65b544f4fc09>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimpleRNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mhx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m         \u001b[0m_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_rnn_impls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[1;34m(self, input, batch_sizes)\u001b[0m\n\u001b[0;32m    173\u001b[0m             raise RuntimeError(\n\u001b[0;32m    174\u001b[0m                 'input must have {} dimensions, got {}'.format(\n\u001b[1;32m--> 175\u001b[1;33m                     expected_input_dim, input.dim()))\n\u001b[0m\u001b[0;32m    176\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m             raise RuntimeError(\n",
      "\u001b[1;31mRuntimeError\u001b[0m: input must have 3 dimensions, got 2"
     ]
    }
   ],
   "source": [
    "output, hidden_layer = model(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([178, 8])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 5])\n",
      "tensor([[0.1611, 0.1577, 0.2954, 0.2022, 0.1837],\n",
      "        [0.1550, 0.1613, 0.3001, 0.1953, 0.1882],\n",
      "        [0.1492, 0.1650, 0.3044, 0.1888, 0.1926],\n",
      "        [0.1440, 0.1685, 0.3079, 0.1828, 0.1968],\n",
      "        [0.1392, 0.1719, 0.3109, 0.1773, 0.2007],\n",
      "        [0.1351, 0.1750, 0.3133, 0.1725, 0.2042],\n",
      "        [0.1315, 0.1777, 0.3152, 0.1683, 0.2073],\n",
      "        [0.1286, 0.1801, 0.3166, 0.1649, 0.2099],\n",
      "        [0.1263, 0.1820, 0.3176, 0.1622, 0.2119],\n",
      "        [0.1247, 0.1834, 0.3183, 0.1602, 0.2134],\n",
      "        [0.1237, 0.1842, 0.3187, 0.1591, 0.2142],\n",
      "        [0.1234, 0.1845, 0.3189, 0.1587, 0.2146],\n",
      "        [0.1237, 0.1842, 0.3187, 0.1591, 0.2142],\n",
      "        [0.1247, 0.1834, 0.3183, 0.1602, 0.2134],\n",
      "        [0.1263, 0.1820, 0.3176, 0.1622, 0.2119]], grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "1D target tensor expected, multi-target not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-103-bd4097c3095b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;31m# calculate loss gradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    946\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m--> 948\u001b[1;33m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2420\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2421\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2422\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2216\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[0;32m   2217\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2218\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2219\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2220\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: 1D target tensor expected, multi-target not supported"
     ]
    }
   ],
   "source": [
    "\n",
    "# average training loss,\n",
    "# one value per iteration (averaged over all batches in one iteration)\n",
    "avg_train_loss = []\n",
    "# average validation loss, \n",
    "# one value per iteration (averaged over all batches in one iteration)\n",
    "avg_val_loss = []\n",
    "# record the lowest validation loss, \n",
    "# used to determine early stopping (best model)\n",
    "best_val_score = float('inf')\n",
    "net = simpleRNN(input_size, hidden_size)\n",
    "# TODO4: define loss function\n",
    "#       define optimizer\n",
    "#       for each iteration, iteratively train all batches\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "#optimizer = SGD(net.parameters(), lr=learning_rate) # for Q5a\n",
    "optimizer = torch.optim.Adam(list(net.parameters()), lr=learning_rate) # for Q5b\n",
    "\n",
    "i = 0\n",
    "count = 0 # early stopping counter\n",
    "while i < num_iter:\n",
    "    # TODO5: implement your training and early stopping\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    for _, (X, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = net(X)\n",
    "        print(output)\n",
    "        loss = loss_function(output, y.long())\n",
    "        # calculate loss gradient\n",
    "        loss.backward()\n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "        # append loss\n",
    "        train_loss.append(loss)\n",
    "        #print('train loss =', train_loss)\n",
    "    avg_train_loss.append(torch.mean(torch.tensor(train_loss)))\n",
    "    \n",
    "    for _, (X,y) in enumerate(val_loader):\n",
    "        output = net(X)\n",
    "        loss = loss_function(output, y.long()) #logistic_loss((X,y), net)\n",
    "        val_loss.append(loss)\n",
    "    avg_val = torch.mean(torch.tensor(val_loss))\n",
    "    avg_val_loss.append(avg_val)\n",
    "    # TODO6: save the best model with lowest validation loss and load it to do testing\n",
    "    if avg_val < best_val_score:\n",
    "        best_val_score = avg_val\n",
    "        #print('here')\n",
    "        #torch.save(net.state_dict(),\"checkpoint.pt\")\n",
    "        count = 0\n",
    "    else:\n",
    "        count += 1\n",
    "    if count == 5:\n",
    "        break\n",
    "    i += 1\n",
    "#net = simpleRNN()\n",
    "#net.load_state_dict(torch.load(\"checkpoint.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-64156d691fe5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline(tf.keras.Model):\n",
    "  def __init__(self, label_index=None):\n",
    "    super().__init__()\n",
    "    self.label_index = label_index\n",
    "\n",
    "  def call(self, inputs):\n",
    "    if self.label_index is None:\n",
    "      return inputs\n",
    "    result = inputs[:, :, self.label_index]\n",
    "    return result[:, :, tf.newaxis]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dumpster 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MyRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.in2hidden = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.in2output = nn.Linear(input_size + hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x, hidden_state):\n",
    "        #combined = torch.cat((x, hidden_state), 1)\n",
    "        hidden = torch.sigmoid(self.in2hidden(x))\n",
    "        output = self.in2output(hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return nn.init.kaiming_uniform_(torch.empty(1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 5\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = MyRNN(8, hidden_size, 1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3331, 0.3486, 0.0727, 0.1045, 0.1412])\n",
      "tensor([0.4761, 0.5173, 0.4744, 0.5087, 0.6027], grad_fn=<SigmoidBackward>)\n",
      "tensor([0.5079, 0.5627, 0.4546, 0.5444, 0.6583], grad_fn=<SigmoidBackward>)\n",
      "tensor([0.5100, 0.5713, 0.4519, 0.5511, 0.6674], grad_fn=<SigmoidBackward>)\n",
      "tensor([0.5101, 0.5731, 0.4528, 0.5542, 0.6727], grad_fn=<SigmoidBackward>)\n",
      "tensor([0.5103, 0.5743, 0.4539, 0.5569, 0.6773], grad_fn=<SigmoidBackward>)\n",
      "tensor([0.5105, 0.5753, 0.4550, 0.5593, 0.6815], grad_fn=<SigmoidBackward>)\n",
      "tensor([0.5107, 0.5763, 0.4560, 0.5614, 0.6852], grad_fn=<SigmoidBackward>)\n",
      "tensor([0.5108, 0.5770, 0.4568, 0.5632, 0.6883], grad_fn=<SigmoidBackward>)\n",
      "tensor([0.5110, 0.5777, 0.4574, 0.5647, 0.6907], grad_fn=<SigmoidBackward>)\n",
      "tensor([0.5111, 0.5782, 0.4578, 0.5657, 0.6925], grad_fn=<SigmoidBackward>)\n",
      "tensor([0.5112, 0.5785, 0.4581, 0.5664, 0.6936], grad_fn=<SigmoidBackward>)\n",
      "tensor([0.5112, 0.5786, 0.4582, 0.5666, 0.6940], grad_fn=<SigmoidBackward>)\n",
      "tensor([0.5112, 0.5786, 0.4580, 0.5665, 0.6937], grad_fn=<SigmoidBackward>)\n",
      "tensor([0.5112, 0.5784, 0.4577, 0.5659, 0.6927], grad_fn=<SigmoidBackward>)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-69e3140b7afa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[1;31m#print(hidden_state.size())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    946\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m--> 948\u001b[1;33m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2420\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2421\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2422\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlog_softmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1589\u001b[0m         \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'log_softmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1590\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1591\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "print_interval = 3000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (name, label) in enumerate(train_loader):\n",
    "        hidden_state = F.softmax(model.init_hidden(), dim=1).view(-1)\n",
    "        for char in name:\n",
    "            #print(char)\n",
    "            print(hidden_state)\n",
    "            #print(hidden_state.size())\n",
    "            output, hidden_state = model(char, hidden_state)\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i + 1) % print_interval == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
    "                f\"Step [{i + 1}/{len(train_loader)}], \"\n",
    "                f\"Loss: {loss.item():.4f}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dumpster 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model implementation\n",
    "# Vanilla RNN\n",
    "from torch import nn\n",
    "class VanillaRNN(nn.Module):\n",
    "    def __init__(self, input_dims, num_nodes, num_layers, output_dims, dropout_prob):\n",
    "        super(VanillaRNN, self).__init__()\n",
    "\n",
    "        self.num_nodes = num_nodes\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.vanilla_rnn = nn.RNN(input_dims, num_nodes, num_layers, batch_first=True, dropout=dropout_prob)\n",
    "        self.fc = nn.Linear(num_nodes, output_dims) # fully connected layer\n",
    "        #print('after fc')\n",
    "    \n",
    "    def forward(self, x):\n",
    "        hidden_0 = torch.zeros(self.num_layers, x.size(0), self.num_nodes).requires_grad_()\n",
    "        \n",
    "        forward_out, hidden_0 = self.vanilla_rnn(x, hidden_0.detach()) # forward propagation\n",
    "        \n",
    "        forward_out = forward_out[:, -1, :] # reshape the output for the fc\n",
    "        out = self.fc(forward_out)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimization:\n",
    "    def __init__(self, model, loss_func, optimizer):\n",
    "        self.model = model\n",
    "        self.loss_func = loss_func\n",
    "        self.optimizer = optimizer\n",
    "        self.train_losses = np.array([])\n",
    "        self.val_losses = np.array([])\n",
    "    \n",
    "    def train_step(self, x, y):\n",
    "        #print('train step ', x)\n",
    "        self.model.train()\n",
    "        yhat = self.model(x) # preds\n",
    "        loss = self.loss_func(y, yhat)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        self.optimizer.zero_grad()\n",
    "        return loss.item()\n",
    "\n",
    "    def train(self, train_loader, val_loader, batch_size=7, n_epochs=50, n_feats=1):\n",
    "        val_values = np.array([])\n",
    "        val_preds = np.array([])\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            batch_losses = np.array([])\n",
    "            #print(epoch)\n",
    "            for x_batch, y_batch in train_loader:\n",
    "                #print('train ', x_batch)\n",
    "                x_batch = x_batch.view([batch_size, -1, n_feats]).to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                loss = self.train_step(x_batch, y_batch)\n",
    "                batch_losses = np.append(batch_losses, loss)\n",
    "            train_loss = np.mean(batch_losses)\n",
    "            self.train_losses = np.append(self.train_losses, train_loss)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                batch_val_losses = np.array([])\n",
    "                for x_val, y_val in val_loader:\n",
    "                    x_val = x_val.view([batch_size, -1, n_feats]).to(device)\n",
    "                    y_val = y_val.to(device)\n",
    "\n",
    "                    self.model.eval()\n",
    "                    yhat = self.model(x_val)\n",
    "                    val_loss = self.loss_func(y_val, yhat).item()\n",
    "                    batch_val_losses = np.append(batch_val_losses, val_loss)\n",
    "                    \n",
    "                val_loss = np.mean(batch_val_losses)\n",
    "                self.val_losses = np.append(self.val_losses, val_loss)\n",
    "\n",
    "                \n",
    "            if (epoch <= 10) | (epoch % 50 == 0):\n",
    "                print(f'Training loss: {train_loss}, val loss {val_loss}')   \n",
    "        \n",
    "        val_values = np.append(val_values, y_val.to(device).detach().numpy())\n",
    "        val_preds = np.append(val_preds, yhat.to(device).detach().numpy())  \n",
    "        \n",
    "        return val_values, val_preds\n",
    "    \n",
    "    def evaluate(self, test_loader, batch_size=1, n_feats=1):\n",
    "        with torch.no_grad():\n",
    "            test_preds = np.array([])\n",
    "            test_vals = np.array([])\n",
    "\n",
    "            for x_test, y_test in test_loader.dataset:\n",
    "                x_test = x_test.view([batch_size, -1, n_feats]).to(device)\n",
    "                y_test = y_test.to(device)\n",
    "                self.model.eval()\n",
    "                yhat = self.model(x_test)\n",
    "\n",
    "                test_vals = np.append(test_vals, y_test.to(device).detach().numpy())\n",
    "                test_preds = np.append(test_preds, yhat.to(device).detach().numpy())\n",
    "\n",
    "        return test_vals, test_preds\n",
    "    \n",
    "\n",
    "    def plot_losses(self):\n",
    "        plt.plot(self.train_losses, label=\"train loss\")\n",
    "        plt.plot(self.val_losses, label='Val loss')\n",
    "        plt.legend()\n",
    "        plt.title('losses')\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dims = 8\n",
    "num_layers = 5\n",
    "num_nodes = 5\n",
    "output_dims = 1\n",
    "batch_size = 1\n",
    "n_epochs = 150\n",
    "dropout = 0.1\n",
    "lr = 1e-3\n",
    "model_params = {\n",
    "    'input_dims': input_dims,\n",
    "    'num_nodes': num_nodes,\n",
    "    'num_layers': num_layers,\n",
    "    'output_dims': output_dims,\n",
    "    'dropout_prob': dropout\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:93: UserWarning: Using a target size (torch.Size([1, 1, 1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.02749914878451019, val loss 0.05075409888421129\n",
      "Training loss: 0.014311034805579905, val loss 0.04688009569708933\n",
      "Training loss: 0.011131797649901812, val loss 0.04512728175660908\n",
      "Training loss: 0.009021746109536277, val loss 0.046359490828226074\n",
      "Training loss: 0.00840583720689247, val loss 0.04547200536967924\n",
      "Training loss: 0.008102528121836082, val loss 0.04626387992761279\n",
      "Training loss: 0.00864731187717112, val loss 0.04518574586250638\n",
      "Training loss: 0.008018946646808776, val loss 0.045299671790343804\n",
      "Training loss: 0.008189290643444144, val loss 0.04632596466565292\n",
      "Training loss: 0.007944235893492607, val loss 0.045302414254054124\n",
      "Training loss: 0.008094820896614627, val loss 0.04531731741540384\n",
      "Training loss: 0.007651486275341746, val loss 0.04515059762353065\n",
      "Training loss: 0.00790987548892357, val loss 0.0473318172981275\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch import optim\n",
    "import random\n",
    "model = VanillaRNN(**model_params)\n",
    "loss_func = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "opt = Optimization(model=model, loss_func=loss_func, optimizer=optimizer)\n",
    "val_values_vanilla, val_preds_vanilla = opt.train(train_loader, val_loader, batch_size=batch_size, n_epochs=n_epochs, n_feats=input_dims)\n",
    "opt.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output():\n",
    "    test_values_vanilla, test_preds_vanilla = opt.evaluate(test_loader_one, batch_size=batch_size, n_feats=input_dims)\n",
    "    \n",
    "    out = pd.DataFrame({\n",
    "        'test_val': test_values_vanilla,\n",
    "        'test_pred': test_preds_vanilla\n",
    "    })\n",
    "\n",
    "    sns.lineplot(data=out)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "out = output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     -0.001906\n",
       "1     -0.001941\n",
       "2     -0.001966\n",
       "3     -0.001983\n",
       "4     -0.001996\n",
       "         ...   \n",
       "144   -0.001425\n",
       "145   -0.001633\n",
       "146   -0.001770\n",
       "147   -0.001856\n",
       "148   -0.001911\n",
       "Name: test_pred, Length: 149, dtype: float64"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['test_pred'][:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dumpster 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [100/446], Loss: 0.3194\n",
      "Epoch [1/2], Step [200/446], Loss: 0.1645\n",
      "Epoch [1/2], Step [300/446], Loss: 0.0998\n",
      "Epoch [1/2], Step [400/446], Loss: 0.1492\n",
      "Epoch [2/2], Step [100/446], Loss: 0.0513\n",
      "Epoch [2/2], Step [200/446], Loss: 0.0405\n",
      "Epoch [2/2], Step [300/446], Loss: 0.0329\n",
      "Epoch [2/2], Step [400/446], Loss: 0.1335\n",
      "Accuracy of the network on the test data: 85.90604026845638 %\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 1\n",
    "num_classes = 1\n",
    "input_size = 8\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(RNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        # -> x needs to be: (batch_size, seq, input_size)\n",
    "        \n",
    "        # or:\n",
    "        #self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        #self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Set initial hidden states (and cell states for LSTM)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        \n",
    "        # x: (n, 28, 28), h0: (2, n, 128)\n",
    "        \n",
    "        # Forward propagate RNN\n",
    "        out, _ = self.rnn(x, h0)  \n",
    "        # or:\n",
    "        #out, _ = self.lstm(x, (h0,c0))  \n",
    "        \n",
    "        # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # out: (n, 28, 128)\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = out[:, -1, :]\n",
    "        # out: (n, 128)\n",
    "         \n",
    "        out = self.fc(out)\n",
    "        # out: (n, 10)\n",
    "        return torch.sigmoid(out)\n",
    "\n",
    "model = RNN(input_size, hidden_size, num_layers).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "# Train the model\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # origin shape: [N, 1, 28, 28]\n",
    "        # resized: [N, 28, 28]\n",
    "        images = images.reshape(-1, batch_size, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        #print(labels[0])\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "test_output = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, batch_size, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        test_output = test_output + [predicted]\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the test data: {acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0])]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
