{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sqlite3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for RNN\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data structuring and cleaning libraries\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import datetime\n",
    "import time\n",
    "from datetime import date, timedelta\n",
    "\n",
    "# General Libraries\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# Model Libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Other Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame from User 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '../data/raw/user1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "time_df = []\n",
    "\n",
    "for filename in os.listdir(filepath):\n",
    "    if 'temp' in filename:\n",
    "        continue\n",
    "    if filename == '.ipynb_checkpoints':\n",
    "        continue\n",
    "    cnx = sqlite3.connect(filepath + filename)\n",
    "    cnx.text_factory = lambda b: b.decode(errors = 'ignore') #https://stackoverflow.com/questions/22751363/sqlite3-operationalerror-could-not-decode-to-utf-8-column\n",
    "    df_string = pd.read_sql_query(\"SELECT * FROM COUNTERS_STRING_TIME_DATA\", cnx)\n",
    "    df_ull = pd.read_sql_query(\"SELECT * FROM COUNTERS_ULL_TIME_DATA\", cnx)\n",
    "    df_data = pd.concat([df_string, df_ull], ignore_index = True)\n",
    "    start_val = pd.DataFrame({'MEASUREMENT_TIME': df_data.loc[0][0], 'ID_INPUT': 4, 'VALUE': 's0', 'PRIVATE_DATA': 0}, index =[0])\n",
    "    df_data = pd.concat([start_val, df_data])\n",
    "    data.append(pd.DataFrame(df_data))\n",
    "    schema = pd.DataFrame(pd.read_sql_query(\"SELECT * FROM INPUTS\", cnx))\n",
    "    \n",
    "    # get actual start time\n",
    "    time_diff = pd.read_sql_query(\"SELECT * FROM DB_META_DATA\", cnx)\n",
    "    utc_open = pd.to_datetime(time_diff[time_diff['KEY'] == 'OPEN_TIME_UTC']['VALUE'].iloc[0])\n",
    "    local_open = pd.to_datetime(time_diff[time_diff['KEY'] == 'OPEN_TIME_LOCAL']['VALUE'].iloc[0])\n",
    "    time_difference = utc_open - local_open\n",
    "    \n",
    "    time_sub = df_data[df_data['ID_INPUT'] == 4].copy()\n",
    "    time_sub['MEASUREMENT_TIME'] = pd.to_datetime(time_sub['MEASUREMENT_TIME'])\n",
    "    time_sub['MEASUREMENT_TIME'] = time_sub['MEASUREMENT_TIME'] - time_difference\n",
    "    time_sub['Time_Used'] = time_sub['MEASUREMENT_TIME'].diff().dt.total_seconds()\n",
    "    time_sub['Time_Used'] = time_sub['Time_Used'].shift(periods = -1)\n",
    "    time_sub = time_sub.drop(columns = ['PRIVATE_DATA', 'ID_INPUT'])\n",
    "    time_df.append(time_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(data, ignore_index = True)\n",
    "\n",
    "df['MEASUREMENT_TIME'] = pd.to_datetime(df['MEASUREMENT_TIME'])\n",
    "df['PRIVATE_DATA'] = df['PRIVATE_DATA'].astype(int)\n",
    "df['VALUE'] = df['VALUE'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_time_df = pd.concat(time_df, ignore_index = True)\n",
    "all_time_df = all_time_df.fillna(0)\n",
    "all_time_df['Hour'] = all_time_df['MEASUREMENT_TIME'].dt.hour\n",
    "all_time_df['Date'] = all_time_df[\"MEASUREMENT_TIME\"].astype(str).apply(lambda x: x[:10])\n",
    "all_time_df['Minute'] = all_time_df['MEASUREMENT_TIME'].dt.minute\n",
    "all_time_df['Day'] = all_time_df['MEASUREMENT_TIME'].dt.day\n",
    "all_time_df['Month'] = all_time_df['MEASUREMENT_TIME'].dt.month\n",
    "all_time_df['Day_Week'] = all_time_df['MEASUREMENT_TIME'].dt.day_name()\n",
    "all_time_df = all_time_df.assign(Week_Year = all_time_df['MEASUREMENT_TIME'].apply(lambda x: x.strftime(\"%W\")))\n",
    "all_time_df = all_time_df.assign(Week_Day = all_time_df['Week_Year'] + '_' + all_time_df['Day_Week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_per_week_day = all_time_df.copy()\n",
    "time_per_week_day['Time_Used'] = time_per_week_day['Time_Used'] / 60 / 60\n",
    "time_per_week_day = time_per_week_day.groupby(\"Week_Day\").apply(lambda x: x.groupby(\"VALUE\")[\"Time_Used\"].sum())\n",
    "time_per_week_day = pd.DataFrame(time_per_week_day).reset_index(level=1, inplace=False)\n",
    "df_pivot = time_per_week_day.pivot_table(index = 'Week_Day', columns='VALUE', values='Time_Used').fillna(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering for Bidirectional LSTM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find delta time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "import datetime\n",
    "from datetime import timedelta, date\n",
    "\n",
    "def date_range(start, end):\n",
    "    dates = []\n",
    "    delta = end - start\n",
    "    for i in range(delta.days + 2):\n",
    "        date = start + timedelta(days=i)\n",
    "        date = date.strftime(\"%Y-%m-%d\")\n",
    "        dates.append(date)\n",
    "    return dates\n",
    "\n",
    "all_columns = [x for x in range(0,24)]\n",
    "all_columns.append('Total_Usage')\n",
    "all_index = date_range(all_time_df['MEASUREMENT_TIME'].min(), all_time_df['MEASUREMENT_TIME'].max())\n",
    "apps = {}\n",
    "for app_name in all_time_df['VALUE'].unique():\n",
    "    if app_name == 's0':\n",
    "        continue\n",
    "    app = all_time_df[all_time_df['VALUE'] == app_name]\n",
    "    #print(app)\n",
    "    app = app.reset_index()\n",
    "    zero_data = np.zeros(shape=(len(all_index),len(all_columns)))\n",
    "    app_df = pd.DataFrame(zero_data, index = all_index, columns = all_columns)\n",
    "    for x in range(len(app)):\n",
    "        timestamp = app.loc[x][\"MEASUREMENT_TIME\"]\n",
    "        usage = app.loc[x]['Time_Used']\n",
    "        end_timestamp = timestamp + datetime.timedelta(seconds = usage)\n",
    "        start_hour = app.loc[x]['Hour']\n",
    "        end_hour = int(end_timestamp.strftime(\"%H\"))\n",
    "        date = app.loc[x]['Date']\n",
    "        if start_hour == end_hour:\n",
    "            app_df.loc[date][start_hour] += usage\n",
    "            app_df.loc[date]['Total_Usage'] += usage\n",
    "        else:\n",
    "            remaining_seconds = 3600 - (app.loc[x]['Minute'] * 60 + int(timestamp.strftime(\"%S\")))\n",
    "            app_df.loc[date][start_hour] += remaining_seconds\n",
    "            app_df.loc[date]['Total_Usage'] += remaining_seconds\n",
    "            overflow = usage - remaining_seconds\n",
    "            curr_hour = start_hour + 1\n",
    "            while overflow > 3600:\n",
    "                if curr_hour > 23:\n",
    "                    date = app.loc[x][\"MEASUREMENT_TIME\"] + datetime.timedelta(days = 1)\n",
    "                    date = date.strftime(\"%Y-%m-%d\")\n",
    "                    curr_hour = 0\n",
    "                app_df.loc[date][curr_hour] += 3600\n",
    "                app_df.loc[date]['Total_Usage'] += 3600\n",
    "                curr_hour = curr_hour + 1\n",
    "                overflow -= 3600\n",
    "\n",
    "            if curr_hour > 23:\n",
    "                date = app.loc[x][\"MEASUREMENT_TIME\"] + datetime.timedelta(days = 1)\n",
    "                date = date.strftime(\"%Y-%m-%d\")\n",
    "                curr_hour = 0\n",
    "            app_df.loc[date][curr_hour] += overflow\n",
    "            app_df.loc[date]['Total_Usage'] += overflow\n",
    "            \n",
    "    apps[app_name] = app_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>Total_Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2395.514</td>\n",
       "      <td>599.682</td>\n",
       "      <td>1613.008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1327.671</td>\n",
       "      <td>3440.171</td>\n",
       "      <td>3354.687</td>\n",
       "      <td>3560.505</td>\n",
       "      <td>3545.317</td>\n",
       "      <td>34029.454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...        15       16  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  2395.514  599.682   \n",
       "\n",
       "         17   18        19        20        21        22        23  \\\n",
       "0  1613.008  0.0  1327.671  3440.171  3354.687  3560.505  3545.317   \n",
       "\n",
       "   Total_Usage  \n",
       "0    34029.454  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apps['chrome.exe'].head(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "- Currently, for bidirectional LSTM model, only the lookback feature engineering is used"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a). One-hot encoding the day-of-the-week (Mon, ...) and sin(hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oh_day_sin_hr(apps, app_name):\n",
    "    day = 24\n",
    "    hours_incr = np.arange(24) + 1\n",
    "    sin_hrs = np.round(np.sin(hours_incr * (np.pi / day)),3)\n",
    "    \n",
    "    one_hot_day_encoded = {\n",
    "        'Monday': [1,0,0,0,0,0,0],\n",
    "        'Tuesday': [0,1,0,0,0,0,0],\n",
    "        'Wednesday': [0,0,1,0,0,0,0],\n",
    "        'Thursday': [0,0,0,1,0,0,0],\n",
    "        'Friday': [0,0,0,0,1,0,0],\n",
    "        'Saturday': [0,0,0,0,0,1,0],\n",
    "        'Sunday': [0,0,0,0,0,0,1]\n",
    "    }\n",
    "    apps[app_name]['date'] = all_time_df['Date'].unique()\n",
    "    apps[app_name]['Day_Week'] = pd.to_datetime(pd.Series(all_time_df['Date'].unique())).dt.day_name()\n",
    "    apps[app_name]['Day_Week'] = apps[app_name]['Day_Week'].apply(lambda x: one_hot_day_encoded[x])\n",
    "\n",
    "    vanilla_df = apps[app_name]\n",
    "    X = []\n",
    "    y = np.array([])\n",
    "    for row in vanilla_df.iterrows():\n",
    "        #print(row[1])\n",
    "        feats = []\n",
    "        for hr in sin_hrs:\n",
    "            feats = feats + [np.append(hr, row[1]['Day_Week'])]\n",
    "        targets = row[1][:24]\n",
    "        #print(np.array(feats).shape)\n",
    "        X = X + feats\n",
    "        y = np.append(y, np.array(targets))\n",
    "    \n",
    "    X = np.array(X)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b). Sin(hr) only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sin_hr(apps, app_name):\n",
    "    day = 24\n",
    "    hours_incr = np.arange(24) + 1\n",
    "    sin_hrs = np.round(np.sin(hours_incr * (np.pi / day)),3)\n",
    "\n",
    "    vanilla_df = apps[app_name]\n",
    "    X = []\n",
    "    y = np.array([])\n",
    "    for row in vanilla_df.iterrows():\n",
    "        #print(row[1])\n",
    "        feats = []\n",
    "        for hr in sin_hrs:\n",
    "            feats = feats + [hr]\n",
    "        targets = row[1][:24]\n",
    "        #print(np.array(feats).shape)\n",
    "        X = X + feats\n",
    "        y = np.append(y, np.array(targets))\n",
    "    \n",
    "    X = np.array(X)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c). One-hot encoding hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oh_hr(apps, app_name):\n",
    "    day = 24\n",
    "    hours_incr = np.arange(24) + 1\n",
    "    hrs = []\n",
    "    for i in range(day):\n",
    "        oh = np.zeros(day)\n",
    "        oh[i] = 1\n",
    "        hrs = hrs + [oh]\n",
    "\n",
    "    vanilla_df = apps[app_name]\n",
    "    X = []\n",
    "    y = np.array([])\n",
    "    for row in vanilla_df.iterrows():\n",
    "        #print(row[1])\n",
    "        feats = []\n",
    "        for hr in hrs:\n",
    "            feats = feats + [hr]\n",
    "        targets = row[1][:24]\n",
    "        #print(np.array(feats).shape)\n",
    "        X = X + feats\n",
    "        y = np.append(y, np.array(targets))\n",
    "    \n",
    "    X = np.array(X)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d). Lookback (time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feats(chrome, time_step, test_ratio=0.2):\n",
    "    obser = []\n",
    "    for r in chrome.iterrows():\n",
    "        obser.append(list(r[1][:24]))\n",
    "\n",
    "    all_obsers = []\n",
    "    for elems in obser:\n",
    "        for elem in elems:\n",
    "            all_obsers.append(elem)\n",
    "\n",
    "    n = len(all_obsers)\n",
    "    in_feats = []\n",
    "    out_target = []\n",
    "    for i in range(n - time_step):\n",
    "        for j in range(i, i + time_step):\n",
    "            if j + time_step < n:\n",
    "                in_feats.append(all_obsers[j: j + time_step])\n",
    "                out_target.append(all_obsers[j + time_step])\n",
    "    \n",
    "    \n",
    "    \n",
    "    return train_test_split(in_feats, out_target, test_size=test_ratio, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X_test, y_test, time_step=3, n_features=1):\n",
    "    predicted = []\n",
    "    for x in X_test:\n",
    "        x_input = np.array(x)\n",
    "        x_input = x_input.reshape((1, time_step, n_features))\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "        predicted.append(yhat)\n",
    "    \n",
    "    preds = []\n",
    "    for i in predicted:\n",
    "        preds.append(i[0][0])\n",
    "\n",
    "    out_df = pd.DataFrame({\n",
    "        'test_val': y_test,\n",
    "        'test_pred': preds\n",
    "    })    \n",
    "\n",
    "    sns.lineplot(out_df)\n",
    "\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_acc(out_df, at_most = 180):\n",
    "    mse = np.sqrt(mean_squared_error(out_df['test_val'], out_df['test_pred']))\n",
    "    print('RMSE =', mse)\n",
    "\n",
    "    indices = pd.Series(np.arange(out_df.shape[0]))\n",
    "    out_df['acc'] = indices.apply(lambda x: 1 if abs(out_df['test_val'][x] - out_df['test_pred'][x]) <= at_most else 0)\n",
    "    acc = (sum(out_df['acc']) / out_df.shape[0])*100\n",
    "    print('ACC =', acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Working) Experiment 1: Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Bidirectional\n",
    "import tensorflow as tf\n",
    "\n",
    "chrome = apps['chrome.exe']\n",
    "time_step = 5\n",
    "n_features = 1\n",
    "X_train, X_test, y_train, y_test = feats(chrome, time_step=5, test_ratio=0.2)\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(128, activation='relu'), input_shape=(time_step, n_features)))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.MeanAbsoluteError(\n",
    "    reduction=\"auto\", name=\"mean_absolute_error\"\n",
    "), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=200, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = predict(model, X_test, y_test, time_step=5, n_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc(out_df, at_most = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "sns.lineplot(out_df[['test_val', 'test_pred']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
